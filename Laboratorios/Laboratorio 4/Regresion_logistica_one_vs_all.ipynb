{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Laboratorio 4(Aplicacion de Regularizacion - Regresion Logistica one-vs-all) Grupo 1\n",
    " <h3>En este laboratorio se hizo el uso del dataset para aplicar la regularización y sin utilizar regularización a la Regresion Logistica one-vs-all, y como siguiente se presento los resultados de ambas experiencias<h3>\n",
    " <HR>\n",
    " <h3>\n",
    "  NOMBRE: POLO ORELLANA BRAYAN SIMON <br>\n",
    "  CARRERA: INGENIERIA DE SISTEMAS <BR>\n",
    "  FECHA: 02/04/2024 <BR>\n",
    "\n",
    "  * [Enlace de invitacion para ser colaborador](https://github.com/bspoloo/SIS420-012024/invitations)\n",
    "  \n",
    "  * [Enlace al git hub](https://github.com/bspoloo/SIS420-012024/tree/main/Laboratorios/Laboratorio%204)\n",
    "  \n",
    "  * [Enlace al Colab](https://colab.research.google.com/github/bspoloo/SIS420-012024/blob/main/Laboratorios/Laboratorio%204/Regresion_logistica_one_vs_all.ipynb?hl=es)\n",
    " <h3>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el laboratorio se hizo uso del para entrenar el modelo de **Regresion Logistica one vs all** aplicando regularizacion y dada la información relacionada con el crédito de una persona, se creo un modelo de aprendizaje automático que pueda clasificar el puntaje crediticio de una persona\n",
    "\n",
    " A lo largo de los años, se han recopilado datos bancarios básicos y mucha información relacionada con el crédito de varias personas. Se quiere construir un sistema inteligente para segregar a las personas en tramos de puntuación crediticia para reducir los esfuerzos manuales. Haciendo uso del siguiente dataset: [credit_score_classification_processed](https://www.kaggle.com/datasets/deepaksaipendyala/credit-score-classification-processed).\n",
    "\n",
    "El archivo `credit_score.csv` contiene un conjunto de datos de entrenamiento para clasificar el puntaje crediticio de una persona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se importo todas las librerias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando la libreria os para manejos de directorios\n",
    "import os\n",
    "\n",
    "# Computacion vectorial y cientifica para python\n",
    "import numpy as np  \n",
    "\n",
    "#importamos pandas para el manejo del dataset, y separarlos dentro de una matriz\n",
    "import pandas as pd\n",
    "\n",
    "#esta tabulate nos sirve para hacer tablas\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Librerias para graficación (trazado de gráficos)\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # -> Necesario para graficar superficies 3D\n",
    "\n",
    "#Para separa el 20% y 80%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modulo de optimizacion en scipy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos del dataset\n",
    "\n",
    "cargamos los datos haciendo el uso de la libreria **Pandas** que  es una herramienta poderosa y versátil utilizada para manipulación y análisis de datos. Ofrece estructuras de datos flexibles y eficientes para trabajar con datos tabulares, como hojas de cálculo en Excel o tablas SQL. Algunas de las funcionalidades clave de pandas incluyen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Month</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.280222</td>\n",
       "      <td>3</td>\n",
       "      <td>284.629162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>34.429817</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>267</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521</td>\n",
       "      <td>4</td>\n",
       "      <td>331.209863</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.458074</td>\n",
       "      <td>5</td>\n",
       "      <td>223.451310</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153</td>\n",
       "      <td>1</td>\n",
       "      <td>341.489231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>27.262259</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>62.430172</td>\n",
       "      <td>6</td>\n",
       "      <td>340.479212</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79800</th>\n",
       "      <td>99991</td>\n",
       "      <td>1</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>20002.88</td>\n",
       "      <td>1929.906667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3571.70</td>\n",
       "      <td>37.140784</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>60.964772</td>\n",
       "      <td>34.662906</td>\n",
       "      <td>0</td>\n",
       "      <td>337.362988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79801</th>\n",
       "      <td>99993</td>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>29.135447</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>58638.000000</td>\n",
       "      <td>180.733095</td>\n",
       "      <td>4</td>\n",
       "      <td>400.104466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802</th>\n",
       "      <td>99997</td>\n",
       "      <td>5</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.546679</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>41.255522</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>24.028477</td>\n",
       "      <td>0</td>\n",
       "      <td>516.809083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79803</th>\n",
       "      <td>99998</td>\n",
       "      <td>4</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>33.638208</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>251.672582</td>\n",
       "      <td>3</td>\n",
       "      <td>319.164979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79804</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>34.192463</td>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>167.163865</td>\n",
       "      <td>6</td>\n",
       "      <td>393.673696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79805 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Month        Age  Occupation  Annual_Income  \\\n",
       "0               1      2  23.000000          13       19114.12   \n",
       "1               2      6  34.429817          13       19114.12   \n",
       "2               3      0  23.000000          13       19114.12   \n",
       "3               4      7  23.000000          13       19114.12   \n",
       "4               5      5  23.000000          13       19114.12   \n",
       "...           ...    ...        ...         ...            ...   \n",
       "79800       99991      1  29.000000           1       20002.88   \n",
       "79801       99993      2  25.000000           9       39628.99   \n",
       "79802       99997      5  25.000000           9       39628.99   \n",
       "79803       99998      4  25.000000           9       39628.99   \n",
       "79804       99999      1  25.000000           9       39628.99   \n",
       "\n",
       "       Monthly_Inhand_Salary  Num_Bank_Accounts  Num_Credit_Card  \\\n",
       "0                4194.170850                3.0              4.0   \n",
       "1                4194.170850                3.0              4.0   \n",
       "2                4194.170850                3.0              4.0   \n",
       "3                1824.843333                3.0              4.0   \n",
       "4                4194.170850                3.0              4.0   \n",
       "...                      ...                ...              ...   \n",
       "79800            1929.906667               10.0              8.0   \n",
       "79801            3359.415833                4.0              6.0   \n",
       "79802            3359.415833                4.0              6.0   \n",
       "79803            3359.415833                4.0              6.0   \n",
       "79804            3359.415833                4.0              6.0   \n",
       "\n",
       "       Interest_Rate  Num_of_Loan  ...  Credit_Mix  Outstanding_Debt  \\\n",
       "0           3.000000          4.0  ...           1            809.98   \n",
       "1           3.000000          4.0  ...           1            809.98   \n",
       "2           3.000000          4.0  ...           1            809.98   \n",
       "3           3.000000          4.0  ...           1            809.98   \n",
       "4           3.000000          4.0  ...           1            809.98   \n",
       "...              ...          ...  ...         ...               ...   \n",
       "79800      29.000000          5.0  ...           0           3571.70   \n",
       "79801       7.000000          2.0  ...           1            502.38   \n",
       "79802      14.546679          2.0  ...           1            502.38   \n",
       "79803       7.000000          2.0  ...           1            502.38   \n",
       "79804       7.000000          2.0  ...           1            502.38   \n",
       "\n",
       "       Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \\\n",
       "0                     31.944960                   0                      1   \n",
       "1                     28.609352                 267                      1   \n",
       "2                     31.377862                 268                      1   \n",
       "3                     24.797347                 269                      1   \n",
       "4                     27.262259                 270                      1   \n",
       "...                         ...                 ...                    ...   \n",
       "79800                 37.140784                  75                      2   \n",
       "79801                 29.135447                 376                      1   \n",
       "79802                 41.255522                 380                      1   \n",
       "79803                 33.638208                 381                      1   \n",
       "79804                 34.192463                 382                      1   \n",
       "\n",
       "       Total_EMI_per_month  Amount_invested_monthly  Payment_Behaviour  \\\n",
       "0                49.574949               118.280222                  3   \n",
       "1                49.574949                81.699521                  4   \n",
       "2                49.574949               199.458074                  5   \n",
       "3                49.574949                41.420153                  1   \n",
       "4                49.574949                62.430172                  6   \n",
       "...                    ...                      ...                ...   \n",
       "79800            60.964772                34.662906                  0   \n",
       "79801         58638.000000               180.733095                  4   \n",
       "79802            35.104023                24.028477                  0   \n",
       "79803            35.104023               251.672582                  3   \n",
       "79804            35.104023               167.163865                  6   \n",
       "\n",
       "       Monthly_Balance  Credit_Score  \n",
       "0           284.629162             2  \n",
       "1           331.209863             2  \n",
       "2           223.451310             2  \n",
       "3           341.489231             2  \n",
       "4           340.479212             2  \n",
       "...                ...           ...  \n",
       "79800       337.362988             1  \n",
       "79801       400.104466             1  \n",
       "79802       516.809083             0  \n",
       "79803       319.164979             1  \n",
       "79804       393.673696             0  \n",
       "\n",
       "[79805 rows x 25 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Haciendo uso de la libreria pandas para leer el dataset, delimitado por \",\"\n",
    "df = pd.read_csv('credit_score.csv', delimiter=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Type_of_Loan</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.280222</td>\n",
       "      <td>3</td>\n",
       "      <td>284.629162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>34.429817</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>267</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521</td>\n",
       "      <td>4</td>\n",
       "      <td>331.209863</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.458074</td>\n",
       "      <td>5</td>\n",
       "      <td>223.451310</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153</td>\n",
       "      <td>1</td>\n",
       "      <td>341.489231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>27.262259</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>62.430172</td>\n",
       "      <td>6</td>\n",
       "      <td>340.479212</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79800</th>\n",
       "      <td>1</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>20002.88</td>\n",
       "      <td>1929.906667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4913</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3571.70</td>\n",
       "      <td>37.140784</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>60.964772</td>\n",
       "      <td>34.662906</td>\n",
       "      <td>0</td>\n",
       "      <td>337.362988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79801</th>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>29.135447</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>58638.000000</td>\n",
       "      <td>180.733095</td>\n",
       "      <td>4</td>\n",
       "      <td>400.104466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802</th>\n",
       "      <td>5</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.546679</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>41.255522</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>24.028477</td>\n",
       "      <td>0</td>\n",
       "      <td>516.809083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79803</th>\n",
       "      <td>4</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>33.638208</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>251.672582</td>\n",
       "      <td>3</td>\n",
       "      <td>319.164979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79804</th>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>34.192463</td>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>167.163865</td>\n",
       "      <td>6</td>\n",
       "      <td>393.673696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79805 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month        Age  Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
       "0          2  23.000000          13       19114.12            4194.170850   \n",
       "1          6  34.429817          13       19114.12            4194.170850   \n",
       "2          0  23.000000          13       19114.12            4194.170850   \n",
       "3          7  23.000000          13       19114.12            1824.843333   \n",
       "4          5  23.000000          13       19114.12            4194.170850   \n",
       "...      ...        ...         ...            ...                    ...   \n",
       "79800      1  29.000000           1       20002.88            1929.906667   \n",
       "79801      2  25.000000           9       39628.99            3359.415833   \n",
       "79802      5  25.000000           9       39628.99            3359.415833   \n",
       "79803      4  25.000000           9       39628.99            3359.415833   \n",
       "79804      1  25.000000           9       39628.99            3359.415833   \n",
       "\n",
       "       Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \\\n",
       "0                    3.0              4.0       3.000000          4.0   \n",
       "1                    3.0              4.0       3.000000          4.0   \n",
       "2                    3.0              4.0       3.000000          4.0   \n",
       "3                    3.0              4.0       3.000000          4.0   \n",
       "4                    3.0              4.0       3.000000          4.0   \n",
       "...                  ...              ...            ...          ...   \n",
       "79800               10.0              8.0      29.000000          5.0   \n",
       "79801                4.0              6.0       7.000000          2.0   \n",
       "79802                4.0              6.0      14.546679          2.0   \n",
       "79803                4.0              6.0       7.000000          2.0   \n",
       "79804                4.0              6.0       7.000000          2.0   \n",
       "\n",
       "       Type_of_Loan  ...  Credit_Mix  Outstanding_Debt  \\\n",
       "0               128  ...           1            809.98   \n",
       "1               128  ...           1            809.98   \n",
       "2               128  ...           1            809.98   \n",
       "3               128  ...           1            809.98   \n",
       "4               128  ...           1            809.98   \n",
       "...             ...  ...         ...               ...   \n",
       "79800          4913  ...           0           3571.70   \n",
       "79801           683  ...           1            502.38   \n",
       "79802           683  ...           1            502.38   \n",
       "79803           683  ...           1            502.38   \n",
       "79804           683  ...           1            502.38   \n",
       "\n",
       "       Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \\\n",
       "0                     31.944960                   0                      1   \n",
       "1                     28.609352                 267                      1   \n",
       "2                     31.377862                 268                      1   \n",
       "3                     24.797347                 269                      1   \n",
       "4                     27.262259                 270                      1   \n",
       "...                         ...                 ...                    ...   \n",
       "79800                 37.140784                  75                      2   \n",
       "79801                 29.135447                 376                      1   \n",
       "79802                 41.255522                 380                      1   \n",
       "79803                 33.638208                 381                      1   \n",
       "79804                 34.192463                 382                      1   \n",
       "\n",
       "       Total_EMI_per_month  Amount_invested_monthly  Payment_Behaviour  \\\n",
       "0                49.574949               118.280222                  3   \n",
       "1                49.574949                81.699521                  4   \n",
       "2                49.574949               199.458074                  5   \n",
       "3                49.574949                41.420153                  1   \n",
       "4                49.574949                62.430172                  6   \n",
       "...                    ...                      ...                ...   \n",
       "79800            60.964772                34.662906                  0   \n",
       "79801         58638.000000               180.733095                  4   \n",
       "79802            35.104023                24.028477                  0   \n",
       "79803            35.104023               251.672582                  3   \n",
       "79804            35.104023               167.163865                  6   \n",
       "\n",
       "       Monthly_Balance  Credit_Score  \n",
       "0           284.629162             2  \n",
       "1           331.209863             2  \n",
       "2           223.451310             2  \n",
       "3           341.489231             2  \n",
       "4           340.479212             2  \n",
       "...                ...           ...  \n",
       "79800       337.362988             1  \n",
       "79801       400.104466             1  \n",
       "79802       516.809083             0  \n",
       "79803       319.164979             1  \n",
       "79804       393.673696             0  \n",
       "\n",
       "[79805 rows x 24 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminamos la primera columan que seria nuestro \"id\" ya que no nos sirve para el analisis, que esa columna es unnamed\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "#ahora tenemos un dataframe\n",
    "#Imprimimos en una tabla el dataset para hacer un analisis mas claro.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis del dataset\n",
    "Hacemos un analisis del dataset mostrando su informacion usando la funcion de `info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79805 entries, 0 to 79804\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Month                     79805 non-null  int64  \n",
      " 1   Age                       79805 non-null  float64\n",
      " 2   Occupation                79805 non-null  int64  \n",
      " 3   Annual_Income             79805 non-null  float64\n",
      " 4   Monthly_Inhand_Salary     79805 non-null  float64\n",
      " 5   Num_Bank_Accounts         79805 non-null  float64\n",
      " 6   Num_Credit_Card           79805 non-null  float64\n",
      " 7   Interest_Rate             79805 non-null  float64\n",
      " 8   Num_of_Loan               79805 non-null  float64\n",
      " 9   Type_of_Loan              79805 non-null  int64  \n",
      " 10  Delay_from_due_date       79805 non-null  int64  \n",
      " 11  Num_of_Delayed_Payment    79805 non-null  float64\n",
      " 12  Changed_Credit_Limit      79805 non-null  int64  \n",
      " 13  Num_Credit_Inquiries      79805 non-null  float64\n",
      " 14  Credit_Mix                79805 non-null  int64  \n",
      " 15  Outstanding_Debt          79805 non-null  float64\n",
      " 16  Credit_Utilization_Ratio  79805 non-null  float64\n",
      " 17  Credit_History_Age        79805 non-null  int64  \n",
      " 18  Payment_of_Min_Amount     79805 non-null  int64  \n",
      " 19  Total_EMI_per_month       79805 non-null  float64\n",
      " 20  Amount_invested_monthly   79805 non-null  float64\n",
      " 21  Payment_Behaviour         79805 non-null  int64  \n",
      " 22  Monthly_Balance           79805 non-null  float64\n",
      " 23  Credit_Score              79805 non-null  int64  \n",
      "dtypes: float64(14), int64(10)\n",
      "memory usage: 14.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mostrando la tabla nos damos cuenta que nuestra Y a predicir es el **Credit_Score**, para tener una mejor vision de la cantidad de clases que existe, se hizo el siguiente codigo:\n",
    "\n",
    "donde separamos nuestra columna Y con `value_counts()` este método de pandas cuenta el número de veces que aparece cada valor único en la columna **Credit_Score** del DataFrame. Devuelve una Serie pandas donde los índices son los valores únicos de la columna **Credit_Score** y los valores son el recuento de ocurrencias de cada valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de caracteristicas es: 23\n",
      "la cantidad de clases es: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Credit_Score\n",
       "1    42470\n",
       "0    23129\n",
       "2    14206\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para contar cuantas clases contiene nuestra columna y\n",
    "class_counts = df[\"Credit_Score\"].value_counts()\n",
    "\n",
    "#para contar cuantas caracteristicas tiene nuestro dataset, obviamente con sin contar nuestra y, por eso lo dropeamos, tambien dropeamos la primera columna que no tiene nombre\n",
    "feactures_counts =df.drop(['Credit_Score'], axis=1)\n",
    "feactures_counts = feactures_counts.shape[1]\n",
    "\n",
    "print(f\"la cantidad de caracteristicas es: { feactures_counts}\")\n",
    "print(f'la cantidad de clases es: 3')\n",
    "\n",
    "#mostramos la cantidad de clases tiene, y en que cantidad\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 3 clases diferentes de puntajes crediticios: etiquetados como 0, 1 y 2.\n",
    "\n",
    "* La clase 1 parece ser la más común, seguida por la clase 0 y luego la clase 2.\n",
    "* El recuento de cada clase es el siguiente:\n",
    "    - Clase 0: 23129 personas.\n",
    "    - Clase 1: 42470 personas.\n",
    "    - Clase 2: 14206 personas.\n",
    "* Este análisis de la distribución de los puntajes crediticios en el conjunto de datos es útil para comprender la proporción de cada clase. Esto puede ser relevante al desarrollar un modelo de clasificación como la Regresión Logística one vs all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#almacenamos la cantidad de caracteristicas en una variable\n",
    "input_layer_size  = feactures_counts;\n",
    "\n",
    "#almacenamos la cantidad de clases en una variable\n",
    "\n",
    "#para este caso no es necesario cambiar los valores de la ultima clase, ya que este cuenta con 0,1,2, \n",
    "# en caso de contener 1,2,3 se tendria que hacer los cambios necesarios para que sea 1,2,0, o simplememte suma 1 a la cantidad de clases.\n",
    "num_labels = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion del 80% de los datos para entrenamiento y 20% para pruebas\n",
    "\n",
    "Se debe tomar en cuenta que cada clase tiene su propia cantidad, por lo cual separarlos directamente en un 80% para entrenamiento y un 20% para test no seria tan efectivo, ya que puede que en el 80% hay mas datos de una clase que las otras, provocando que nuestro modelo no conozca mucho sobre esa clase, por lo cual debe separarse un 80% para entrenamiento y un 20% para pruebas de cada clase.\n",
    "\n",
    "Para este hacemos uso de la libreria **train_test_split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos uso del DataFrame llamado 'df' que contiene nuestros datos datos\n",
    "# y es la columna que contiene las etiquetas de clase (en este caso, 'Credit_Score')\n",
    "\n",
    "#creamos una variable temporal que contentra toda la columna de 'Credit_Score'\n",
    "y_temp = df['Credit_Score']\n",
    "\n",
    "# Para la clase 0\n",
    "\n",
    "#donde y_temp es igual a 0, separamos los datos en train_class_0, test_class_0\n",
    "data_class_0 = df[y_temp == 0]\n",
    "train_class_0, test_class_0 = train_test_split(data_class_0, test_size=0.2, random_state=42)\n",
    "\n",
    "# Para la clase 1\n",
    "\n",
    "#donde y_temp es igual a 1, separamos los datos en train_class_1, test_class_1\n",
    "data_class_1 = df[y_temp == 1]\n",
    "train_class_1, test_class_1 = train_test_split(data_class_1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Para la clase 2\n",
    "\n",
    "#donde y_temp es igual a 2, separamos los datos en train_class_2, test_class_2\n",
    "data_class_2 = df[y_temp == 2]\n",
    "train_class_2, test_class_2 = train_test_split(data_class_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "haciendo conteo de separacion de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la clase 0 tenemos una cantidad de: 23129 donde el 80% es: 18503 y el 20% es: 4626\n",
      "Para la clase 1 tenemos una cantidad de: 42470 donde el 80% es: 33976 y el 20% es: 8494\n",
      "Para la clase 2 tenemos una cantidad de: 14206 donde el 80% es: 11364 y el 20% es: 2842\n",
      "La cantidad total de datos es: 79805\n"
     ]
    }
   ],
   "source": [
    "print(f\"Para la clase 0 tenemos una cantidad de: { data_class_0.shape[0]} donde el 80% es: {train_class_0.shape[0]} y el 20% es: {test_class_0.shape[0]}\")\n",
    "print(f\"Para la clase 1 tenemos una cantidad de: { data_class_1.shape[0]} donde el 80% es: {train_class_1.shape[0]} y el 20% es: {test_class_1.shape[0]}\")\n",
    "print(f\"Para la clase 2 tenemos una cantidad de: { data_class_2.shape[0]} donde el 80% es: {train_class_2.shape[0]} y el 20% es: {test_class_2.shape[0]}\")\n",
    "print(f\"La cantidad total de datos es: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos cada uno en sus X_train, y_train, X_test y y_test respectivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para la parte de entrenamiento, separamos las caracteristicas de la etiqueta\n",
    "\n",
    "#para la clase 0\n",
    "X_train_class_0 = train_class_0.drop(['Credit_Score'], axis=1)\n",
    "y_train_class_0 = train_class_0['Credit_Score']\n",
    "\n",
    "#para la clase 1\n",
    "X_train_class_1 = train_class_1.drop(['Credit_Score'], axis=1)\n",
    "y_train_class_1 = train_class_1['Credit_Score']\n",
    "\n",
    "#para la clase 2\n",
    "X_train_class_2 = train_class_2.drop(['Credit_Score'], axis=1)\n",
    "y_train_class_2 = train_class_2['Credit_Score']\n",
    "\n",
    "#ahora para la parte de pruebas, separamos las caracteristicas de la etiqueta\n",
    "#para la clase 0\n",
    "X_test_class_0 = test_class_0.drop(['Credit_Score'], axis=1)\n",
    "y_test_class_0 = test_class_0['Credit_Score']\n",
    "\n",
    "#para la clase 1\n",
    "X_test_class_1 = test_class_1.drop(['Credit_Score'], axis=1)\n",
    "y_test_class_1 = test_class_1['Credit_Score']\n",
    "\n",
    "#para la clase 2\n",
    "X_test_class_2 = test_class_2.drop(['Credit_Score'], axis=1)\n",
    "y_test_class_2 = test_class_2['Credit_Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora unimos todos en una sola matriz para X y y:\n",
    "pero luego debemos mezclar los datos, haciendo uso de ``np.random.permutation(len(X))`` genera un arreglo de índices permutados aleatoriamente.\n",
    "Luego, estos índices se usan para reorganizar tanto las características como las etiquetas de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando los datos de entrenamiento y pruebas\n",
    "\n",
    "#para los datos de entrenamiento\n",
    "X_train = pd.concat([X_train_class_0, X_train_class_1, X_train_class_2]).values\n",
    "y_train = pd.concat([y_train_class_0, y_train_class_1, y_train_class_2]).values\n",
    "\n",
    "\n",
    "indices_train = np.random.permutation(len(X_train))\n",
    "X_train = X_train[indices_train]\n",
    "y_train = y_train[indices_train]\n",
    "m_train = len(y_train)\n",
    "\n",
    "#para los datos de pruebas\n",
    "X_test = pd.concat([X_test_class_0, X_test_class_1, X_test_class_2]).values\n",
    "y_test = pd.concat([y_test_class_0, y_test_class_1, y_test_class_2]).values\n",
    "\n",
    "indices_test = np.random.permutation(len(X_test))\n",
    "X_test = X_test[indices_test]\n",
    "y_test = y_test[indices_test]\n",
    "m_test = len(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos algunos datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]  X[:, 19]  X[:, 20]  X[:, 21]  X[:, 22]     Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "         3        25        12     15280      4194         3       7        15         4      5255        28         9      4015         3         2       563        34       236         2        51       130         5       211       1\n",
      "         3        34        12     65984      5279         8       3        24         4      5379        15        19      1286        12         2      1377        39       107         2       170       637         2       383       0\n",
      "         3        40        10     20664      1509         9       7        26         6      3650        58        31      2507         6         0      3515        30        97         2        99        63         5       279       1\n",
      "         4        29        15     34899      2923         3       5        15         6       591        16        31      1064         4         2      1553        31       178         2        92       274         3       197       0\n",
      "         4        48         5     19204      1660         5       7        13         3      3826        18        12      3627         7         2       504        27       361         1        35       211         6       210       1\n",
      "         5        25         5     33064      2741         8       3         6         7      4928        12        16      3897         5         2       788        25       216         2       144       208         6       212       1\n",
      "         3        20        10     18053      1231         5       6        13         7      1177        14        12      1195         7         2      1263        24        81         2        57     10000         6       295       1\n",
      "         6        32         8    131578     11206         2       3         3         2      1408        14         2       884        28         1       816        41       257         1       185       281         1       904       2\n",
      "         1        35        13     12876      4194         6       5        15         4      4546         1        19       682         1         2        53        41       351         1        40        22         6       270       1\n",
      "         4        55         4     11249      4194         3       3        12         1      4144        15         9       979         4         1       612        33         0         1         8        13         0       317       2\n",
      " \n",
      "El 80% de ejemplos para entrenamiento son la cantidad de: 63843 de ejemplos\n",
      "El 20% de ejemplos para pruebas son la cantidad de: 15962 de ejemplos\n",
      "La cantidad total de ejemplos es de: 79805 de ejemplos\n"
     ]
    }
   ],
   "source": [
    "#Visualizamos una cantidad de datos de entrenamiento\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]', 'X[:, 19]', 'X[:, 20]', 'X[:, 21]', 'X[:, 22]','Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}'.format(\n",
    "        X_train[i, 0],\n",
    "        X_train[i, 1],\n",
    "        X_train[i, 2], \n",
    "        X_train[i, 3], \n",
    "        X_train[i, 4], \n",
    "        X_train[i, 5], \n",
    "        X_train[i, 6], \n",
    "        X_train[i, 7], \n",
    "        X_train[i, 8], \n",
    "        X_train[i, 9], \n",
    "        X_train[i, 10],\n",
    "        X_train[i, 11],\n",
    "        X_train[i, 12], \n",
    "        X_train[i, 13], \n",
    "        X_train[i, 14], \n",
    "        X_train[i, 15], \n",
    "        X_train[i, 16],\n",
    "        X_train[i, 17],\n",
    "        X_train[i, 18],\n",
    "        X_train[i, 19], \n",
    "        X_train[i, 20], \n",
    "        X_train[i, 21], \n",
    "        X_train[i, 22], \n",
    "        y_train[i]\n",
    "    ))\n",
    "\n",
    "print(\" \")\n",
    "print('El 80% de ejemplos para entrenamiento son la cantidad de: {:.0f} de ejemplos'.format( len(X_train)))\n",
    "print('El 20% de ejemplos para pruebas son la cantidad de: {:.0f} de ejemplos'.format( len(X_test)))\n",
    "print('La cantidad total de ejemplos es de: {:.0f} de ejemplos'.format( len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para la Normalización de caracteristicas\n",
    "\n",
    "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente. En este caso\n",
    "\n",
    "Hacemos el uso de la siguiente funcion para normalizar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    X_norm = X.copy()\n",
    "\n",
    "    #creamos un array de ceros con una longitud igual al número de columnas en el array X. La variable mu y sigma se inicializa como este array de ceros.\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    #Creamos el promedio de cada filaa de X\n",
    "    #media de cada columna\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    \n",
    "    #desviacion estandar de cada fila de X\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    \n",
    "    sigma[sigma == 0] = 1\n",
    "    \n",
    "    #normalizamos los datos con la siguiente formula\n",
    "    X_norm = (X - mu) / sigma\n",
    "\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para el calculo de la sigmoide\n",
    "\n",
    "También conocida como la función logística, es una función matemática que toma cualquier número real como entrada y devuelve un valor en el rango de 0 a 1. Donde nuestra **Z** es nuestra hipotesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z = np.array(z)\n",
    "\n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion de calculo de costo con regularizacion\n",
    "\n",
    "Aplicando la teoria donde nuestra funcion recibira parametros como Theta, x, y y lamda_, donde lamda_ es nuestro parametro de regularizacion.\n",
    "\n",
    "Donde la funcion nos devuelve un costo y nuestro gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrCostFunctionCR(theta, X, y, lambda_):\n",
    "    #creamos una variable m que contiene la longitud de y\n",
    "    m = y.size\n",
    "\n",
    "    # convierte las etiquetas a valores enteros si son boleanos\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "\n",
    "    #inicializamos J y grad\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    #calculamos h haciendo uso de la funcion sigmoid, donde h es nuestra hipotesis\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "\n",
    "    temp = theta\n",
    "    temp[0] = 0\n",
    "\n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
    "\n",
    "    grad = (1 / m) * (h - y).dot(X)\n",
    "    \n",
    "    grad = grad + (lambda_ / m) * temp\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion de One-vs-all con regularizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAllCR(X, y, num_labels, lambda_):\n",
    "    # algunas variables utiles\n",
    "    #m es la longitud de y, n es la cantidad de columnas en X\n",
    "    m, n = X.shape\n",
    "\n",
    "    # inicializamos la matriz de thetas con ceros, y con n+1 columnas que seria nuestro sesgo\n",
    "    all_theta = np.zeros((num_labels, n + 1))\n",
    "\n",
    "    # Agrega unos a la matriz X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    # iteramos sobre cada etiqueta (clase) y entrenamos un clasificador\n",
    "    for c in np.arange(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)\n",
    "        options = {'maxiter': 20000}\n",
    "        res = optimize.minimize(lrCostFunctionCR,\n",
    "                                initial_theta,\n",
    "                                (X, (y == c), lambda_),\n",
    "                                jac=True,\n",
    "                                method='CG',\n",
    "                                options=options)\n",
    "\n",
    "        all_theta[c] = res.x\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion de calculo de costo sin regularizacio\n",
    "\n",
    "Para este caso solo quitamos la sumatoria `+ (lambda_ / (2 * m)) * np.sum(np.square(temp))` a la ecuacion de costo, donde esto se aplicado sin regularizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrCostFunctionSR(theta, X, y):\n",
    "    #creamos una variable m que contiene la longitud de y\n",
    "    m = y.size\n",
    "\n",
    "    # convierte las etiquetas a valores enteros si son boleanos\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "\n",
    "    #inicializamos J y grad\n",
    "    J = 0\n",
    "    \n",
    "    # grad = np.zeros(theta.shape)\n",
    "\n",
    "    #calculamos h haciendo uso de la funcion sigmoid, donde h es nuestra hipotesis\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "\n",
    "    # temp = theta\n",
    "    # temp[0] = 0\n",
    "\n",
    "    # J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
    "\n",
    "    grad = (1 / m) * (h - y).dot(X)\n",
    "    \n",
    "    # grad = grad + (lambda_ / m) * temp\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion de One-vs-all sin regularizacion\n",
    "\n",
    "Como esta funcion sera sin regularizar, ya no se necesita usar el parametro `lambda_` por lo tanto al momento de obtener las thetas para cada clase ya no es necesario enviarle un parametro `lambda_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAllSR(X, y, num_labels):\n",
    "    # algunas variables utiles\n",
    "    #m es la longitud de y, n es la cantidad de columnas en X\n",
    "    m, n = X.shape\n",
    "\n",
    "    # inicializamos la matriz de thetas con ceros, y con n+1 columnas que seria nuestro sesgo\n",
    "    all_theta = np.zeros((num_labels, n + 1))\n",
    "\n",
    "    # Agrega unos a la matriz X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    # iteramos sobre cada etiqueta (clase) y entrenamos un clasificador\n",
    "    for c in np.arange(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)\n",
    "        options = {'maxiter': 20000}\n",
    "        res = optimize.minimize(lrCostFunctionSR,\n",
    "                                initial_theta,\n",
    "                                (X, (y == c)),\n",
    "                                jac=True,\n",
    "                                method='CG',\n",
    "                                options=options)\n",
    "\n",
    "        all_theta[c] = res.x\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para Prediccion One-vs-all\n",
    "Aqui creamos solo la funcion, donde mandamos los parametros de `all_theta` y la `X` que en este caso puede ser las X de prueba, pero antes deben de estar normalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    m = X.shape[0];\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    # inicializamos la matriz de p con ceros\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # añadimos unos a la matriz de X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Usando regularizacion\n",
    "\n",
    "La regularización es una técnica utilizada en el aprendizaje automático para prevenir el **sobreajuste (overfitting)** de un modelo a los datos de entrenamiento.\n",
    "\n",
    "El sobreajuste ocurre cuando un modelo se ajusta demasiado bien a los datos de entrenamiento y captura el ruido o las fluctuaciones aleatorias en los datos en lugar de aprender la verdadera relación subyacente entre las características y la variable objetivo. Esto puede resultar en un rendimiento deficiente del modelo cuando se enfrenta a nuevos datos que no formaban parte del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Clasificacion Multiclase\n",
    "\n",
    "Carga de los datos para la clasificacion multiclase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]  X[:, 19]  X[:, 20]  X[:, 21]  X[:, 22]     Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "         3        25        12     15280      4194         3       7        15         4      5255        28         9      4015         3         2       563        34       236         2        51       130         5       211       1\n",
      "         3        34        12     65984      5279         8       3        24         4      5379        15        19      1286        12         2      1377        39       107         2       170       637         2       383       0\n",
      "         3        40        10     20664      1509         9       7        26         6      3650        58        31      2507         6         0      3515        30        97         2        99        63         5       279       1\n",
      "         4        29        15     34899      2923         3       5        15         6       591        16        31      1064         4         2      1553        31       178         2        92       274         3       197       0\n",
      "         4        48         5     19204      1660         5       7        13         3      3826        18        12      3627         7         2       504        27       361         1        35       211         6       210       1\n",
      "         5        25         5     33064      2741         8       3         6         7      4928        12        16      3897         5         2       788        25       216         2       144       208         6       212       1\n",
      "         3        20        10     18053      1231         5       6        13         7      1177        14        12      1195         7         2      1263        24        81         2        57     10000         6       295       1\n",
      "         6        32         8    131578     11206         2       3         3         2      1408        14         2       884        28         1       816        41       257         1       185       281         1       904       2\n",
      "         1        35        13     12876      4194         6       5        15         4      4546         1        19       682         1         2        53        41       351         1        40        22         6       270       1\n",
      "         4        55         4     11249      4194         3       3        12         1      4144        15         9       979         4         1       612        33         0         1         8        13         0       317       2\n",
      " \n",
      "El 80% de ejemplos para entrenamiento son la cantidad de: 63843 de ejemplos\n",
      "El 20% de ejemplos para pruebas son la cantidad de: 15962 de ejemplos\n",
      "La cantidad total de ejemplos es de: 79805 de ejemplos\n"
     ]
    }
   ],
   "source": [
    "#estos datos seran usados para el entrenamiento\n",
    "X_testCR = X_test.copy()\n",
    "y_testCR = y_test.copy()\n",
    "m_test_CR = len(y_testCR)\n",
    "\n",
    "#estos datos seran usados para el test\n",
    "X_trainCR = X_train.copy()\n",
    "y_trainCR = y_train.copy()\n",
    "m_train_CR = len(y_trainCR)\n",
    "\n",
    "#Visualizamos una cantidad de datos de entrenamiento\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]', 'X[:, 19]', 'X[:, 20]', 'X[:, 21]', 'X[:, 22]','Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}'.format(\n",
    "        X_trainCR[i, 0],\n",
    "        X_trainCR[i, 1],\n",
    "        X_trainCR[i, 2], \n",
    "        X_trainCR[i, 3], \n",
    "        X_trainCR[i, 4], \n",
    "        X_trainCR[i, 5], \n",
    "        X_trainCR[i, 6], \n",
    "        X_trainCR[i, 7], \n",
    "        X_trainCR[i, 8], \n",
    "        X_trainCR[i, 9], \n",
    "        X_trainCR[i, 10],\n",
    "        X_trainCR[i, 11],\n",
    "        X_trainCR[i, 12], \n",
    "        X_trainCR[i, 13], \n",
    "        X_trainCR[i, 14], \n",
    "        X_trainCR[i, 15], \n",
    "        X_trainCR[i, 16],\n",
    "        X_trainCR[i, 17],\n",
    "        X_trainCR[i, 18],\n",
    "        X_trainCR[i, 19], \n",
    "        X_trainCR[i, 20], \n",
    "        X_trainCR[i, 21], \n",
    "        X_trainCR[i, 22], \n",
    "        y_trainCR[i]\n",
    "    ))\n",
    "\n",
    "print(\" \")\n",
    "print('El 80% de ejemplos para entrenamiento son la cantidad de: {:.0f} de ejemplos'.format( len(X_train)))\n",
    "print('El 20% de ejemplos para pruebas son la cantidad de: {:.0f} de ejemplos'.format( len(X_test)))\n",
    "print('La cantidad total de ejemplos es de: {:.0f} de ejemplos'.format( len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Normalizacion de las caracteristicas\n",
    "\n",
    "Se hace uso de la funcion de `featureNormalize(X) ` donde se recibe un parametro de tipo matriz para normalizar cada dato dentro de ella, retornandome la **matriz normalizda**, **sigma(desviacion estandar)**, y mi **mu(media)**.\n",
    "\n",
    "Almacenando los datos normalizados en **X_norm** usando la funcion **featureNormaliza()**, normalizando los datos de X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]  X[:, 19]  X[:, 20]  X[:, 21]  X[:, 22]     Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "     -0.21     -0.97      0.98     -0.11     -0.00     -0.81      0.47      0.05      0.18      0.89      0.47     -0.10      1.21     -0.13      0.97     -0.75      0.33      0.31      0.86     -0.16     -0.26      1.01     -0.90       1\n",
      "     -0.21      0.00      0.98     -0.08      0.37      0.88     -0.89      1.09      0.18      0.95     -0.41     -0.05     -1.00     -0.08      0.97     -0.05      1.31     -0.82      0.86     -0.15     -0.00     -0.51     -0.10       0\n",
      "     -0.21      0.58      0.55     -0.11     -0.92      1.21      0.47      1.32      1.00      0.07      2.48     -0.00     -0.01     -0.11     -1.51      1.80     -0.47     -0.91      0.86     -0.16     -0.29      1.01     -0.58       1\n",
      "      0.22     -0.56      1.63     -0.10     -0.44     -0.81     -0.21      0.05      1.00     -1.48     -0.34     -0.00     -1.18     -0.12      0.97      0.10     -0.23     -0.20      0.86     -0.16     -0.18      0.00     -0.97       0\n",
      "      0.22      1.40     -0.54     -0.11     -0.87     -0.14      0.47     -0.18     -0.22      0.16     -0.21     -0.09      0.90     -0.11      0.97     -0.80     -1.04      1.40     -0.58     -0.17     -0.22      1.52     -0.91       1\n",
      "      0.66     -0.97     -0.54     -0.10     -0.50      0.88     -0.89     -0.98      1.41      0.72     -0.61     -0.07      1.12     -0.12      0.97     -0.55     -1.40      0.13      0.86     -0.15     -0.22      1.52     -0.90       1\n",
      "     -0.21     -1.49      0.55     -0.11     -1.01     -0.14      0.13     -0.18      1.41     -1.18     -0.48     -0.09     -1.07     -0.11      0.97     -0.15     -1.66     -1.05      0.86     -0.16      4.65      1.52     -0.51       1\n",
      "      1.09     -0.25      0.11     -0.03      2.39     -1.15     -0.89     -1.32     -0.63     -1.06     -0.48     -0.13     -1.33      0.00     -0.27     -0.53      1.64      0.49     -0.58     -0.15     -0.18     -1.01      2.35       2\n",
      "     -1.09      0.06      1.20     -0.12     -0.00      0.20     -0.21      0.05      0.18      0.53     -1.35     -0.05     -1.49     -0.14      0.97     -1.19      1.77      1.31     -0.58     -0.16     -0.31      1.52     -0.62       1\n",
      "      0.22      2.12     -0.76     -0.12     -0.00     -0.81     -0.89     -0.29     -1.04      0.32     -0.41     -0.10     -1.25     -0.12     -0.27     -0.71      0.20     -1.76     -0.58     -0.17     -0.31     -1.52     -0.40       2\n"
     ]
    }
   ],
   "source": [
    "X_norm_CR, mu_CR, sigma_CR = featureNormalize(X_trainCR)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]', 'X[:, 19]', 'X[:, 20]', 'X[:, 21]', 'X[:, 22]','Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:8.0f}'.format(\n",
    "        X_norm_CR[i, 0],\n",
    "        X_norm_CR[i, 1],\n",
    "        X_norm_CR[i, 2], \n",
    "        X_norm_CR[i, 3], \n",
    "        X_norm_CR[i, 4], \n",
    "        X_norm_CR[i, 5], \n",
    "        X_norm_CR[i, 6], \n",
    "        X_norm_CR[i, 7], \n",
    "        X_norm_CR[i, 8], \n",
    "        X_norm_CR[i, 9], \n",
    "        X_norm_CR[i, 10],\n",
    "        X_norm_CR[i, 11],\n",
    "        X_norm_CR[i, 12], \n",
    "        X_norm_CR[i, 13], \n",
    "        X_norm_CR[i, 14], \n",
    "        X_norm_CR[i, 15], \n",
    "        X_norm_CR[i, 16],\n",
    "        X_norm_CR[i, 17],\n",
    "        X_norm_CR[i, 18],\n",
    "        X_norm_CR[i, 19], \n",
    "        X_norm_CR[i, 20], \n",
    "        X_norm_CR[i, 21], \n",
    "        X_norm_CR[i, 22], \n",
    "        y_trainCR[i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Clasificacion One-vs-All\n",
    "Aqui estariamos usando un ciclo for para iterar sobre cada una de las clases, luego haciendo uso de `optimize.minimize` que es un método de la biblioteca *scipy* que encuentra el mínimo de una función. En este caso, se trata de minimizar la función de costos de regresión logística `(lrCostFunction)`.\n",
    "\n",
    "Los parámetros iniciales ``(initial_theta)``.\n",
    "Una tupla que contiene los datos de entrenamiento ``(X)``, las etiquetas ``(y == c)``, y el parámetro de regularización ``(lambda_)``.\n",
    "``jac=True`` indica que la función de coste devuelve tanto el coste como el gradiente.\n",
    "El método de optimización ``('CG' significa Gradiente Conjugado).``\n",
    "El diccionario de opciones ``(options)``  que se establece en 1000 para limitar el número máximo de iteraciones del optimizador.\n",
    "\n",
    "\n",
    "Inicializamos nuestra lambda con valor de *0.005*, usamos la funcion de `oneVsAll` donde pasamos los parametros de *X_norm*, *num_labels* que seria la cantidad de clases que tenemos, y nuestro *lanbda* para asi obtener nuestros Thetas para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 24)\n",
      "Thetha 0  para la clase 0: -1.0695169567537348  ;  Thetha 0  para la clase 1: 0.14044304105950767  ;  Thetha 0  para la clase 2: -2.186541760724309\n",
      "Thetha 1  para la clase 0: 0.001099483554564459  ;  Thetha 1  para la clase 1: 0.015678220045970335  ;  Thetha 1  para la clase 2: -0.031174327875785328\n",
      "Thetha 2  para la clase 0: -0.05732951636146707  ;  Thetha 2  para la clase 1: 0.004432269652256636  ;  Thetha 2  para la clase 2: 0.053675683652515446\n",
      "Thetha 3  para la clase 0: 0.006515575044222821  ;  Thetha 3  para la clase 1: -0.0006646074117552987  ;  Thetha 3  para la clase 2: -0.012853200853254738\n",
      "Thetha 4  para la clase 0: -0.022314452167680125  ;  Thetha 4  para la clase 1: 0.018915736516325072  ;  Thetha 4  para la clase 2: -0.0007569880100460452\n",
      "Thetha 5  para la clase 0: -0.07393637295873941  ;  Thetha 5  para la clase 1: -0.00569475992649457  ;  Thetha 5  para la clase 2: 0.09343492800043075\n",
      "Thetha 6  para la clase 0: 0.0057267758499581585  ;  Thetha 6  para la clase 1: 0.14315232476134604  ;  Thetha 6  para la clase 2: -0.1593391572862486\n",
      "Thetha 7  para la clase 0: 0.1506377169190352  ;  Thetha 7  para la clase 1: 0.020848103964031514  ;  Thetha 7  para la clase 2: -0.4539067489187788\n",
      "Thetha 8  para la clase 0: 0.4700853512086889  ;  Thetha 8  para la clase 1: -0.16268666631432935  ;  Thetha 8  para la clase 2: -0.49508252427199845\n",
      "Thetha 9  para la clase 0: 0.06429479899670537  ;  Thetha 9  para la clase 1: 0.03830700417062252  ;  Thetha 9  para la clase 2: -0.17078790044991338\n",
      "Thetha 10  para la clase 0: -0.022417759367925488  ;  Thetha 10  para la clase 1: 0.02006482298695845  ;  Thetha 10  para la clase 2: -0.006755433727529883\n",
      "Thetha 11  para la clase 0: 0.287678000070972  ;  Thetha 11  para la clase 1: -0.014033484602439061  ;  Thetha 11  para la clase 2: -0.4903843811133907\n",
      "Thetha 12  para la clase 0: 0.0007813094553442233  ;  Thetha 12  para la clase 1: 0.009989426560047436  ;  Thetha 12  para la clase 2: -0.017016989956748777\n",
      "Thetha 13  para la clase 0: 0.03090660740766759  ;  Thetha 13  para la clase 1: -0.03467333208040409  ;  Thetha 13  para la clase 2: 0.03021122914395898\n",
      "Thetha 14  para la clase 0: 0.005139516672164181  ;  Thetha 14  para la clase 1: -0.0009803686427819211  ;  Thetha 14  para la clase 2: -0.007575389774211326\n",
      "Thetha 15  para la clase 0: -0.19802437458146044  ;  Thetha 15  para la clase 1: 0.6407264013675681  ;  Thetha 15  para la clase 2: -0.6542815914109166\n",
      "Thetha 16  para la clase 0: 0.05300649134650058  ;  Thetha 16  para la clase 1: 0.06573985117256514  ;  Thetha 16  para la clase 2: -0.2763606458156525\n",
      "Thetha 17  para la clase 0: 0.011181654939103483  ;  Thetha 17  para la clase 1: -0.006392055216834913  ;  Thetha 17  para la clase 2: -0.007899004911733865\n",
      "Thetha 18  para la clase 0: -0.10852669115586946  ;  Thetha 18  para la clase 1: -0.008457963289694889  ;  Thetha 18  para la clase 2: 0.13924040880807756\n",
      "Thetha 19  para la clase 0: 0.034844118797949804  ;  Thetha 19  para la clase 1: 0.11346839324801163  ;  Thetha 19  para la clase 2: -0.2526605716376944\n",
      "Thetha 20  para la clase 0: -0.008509589562424445  ;  Thetha 20  para la clase 1: 0.006267489360037453  ;  Thetha 20  para la clase 2: -0.0018530882892529583\n",
      "Thetha 21  para la clase 0: -0.0017709123627599  ;  Thetha 21  para la clase 1: -0.009518115709138174  ;  Thetha 21  para la clase 2: 0.02052057683451436\n",
      "Thetha 22  para la clase 0: 0.13591537698639689  ;  Thetha 22  para la clase 1: -0.041979794537247525  ;  Thetha 22  para la clase 2: -0.12597997075010497\n",
      "Thetha 23  para la clase 0: 0.07847198160131665  ;  Thetha 23  para la clase 1: 0.002462893221086137  ;  Thetha 23  para la clase 2: -0.11303428867817578\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lambda_ = 1000\n",
    "all_theta_CR = oneVsAllCR(X_norm_CR, y_trainCR, num_labels, lambda_)\n",
    "print(all_theta_CR.shape)\n",
    "\n",
    "#imprimimos todos los thetas para cada clase\n",
    "for i in range(all_theta_CR.shape[1]):\n",
    "    print(\"Thetha\",i,\" para la clase 0:\", all_theta_CR[0,i],\" ; \", \"Thetha\",i,\" para la clase 1:\", all_theta_CR[1,i],\" ; \", \"Thetha\",i,\" para la clase 2:\", all_theta_CR[2,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Validaciones\n",
    "Para hacer las validaciones correspondientes se hizo el uso siguiendo el consejo de 80/20, donde 80% es para la fase de entrenamiento, y 20% es para la fase de prueba.\n",
    "\n",
    "Para este caso de validacion se hizo uso de la funcion de `predictOneVsAll()` creada anteriormente, los siguiente fue normalizar nuestra `X_test` que son el 20% para pruebas, ahora se procedio a normalizarlo haciendo uso de *mu* y *sigma* calculado anteriormente en la funcion de normalizacion.\n",
    "\n",
    "luego se hace uso de `np.mean` donde nos calcula el promedio de los valores booleanos en el array resultante de la comparación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Con los datos de entrenamiento\n",
    "Para este caso se uso los datos de `X_norm` usando la funcion de `predictOneVsAll()`, viendo el resultado de precision nos da un **61.20483%** el cual esta muy lejos de ser un buen modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 61.20483%\n"
     ]
    }
   ],
   "source": [
    "# print(X_test.shape)\n",
    "pred_test_CR = predictOneVsAll(all_theta_CR, X_norm_CR)\n",
    "print('Precision del conjunto de entrenamiento: {:.5f}%'.format(np.mean(pred_test_CR == y_trainCR) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 con los datos de prueba\n",
    "Para este caso se uso los datos de `X_test`, luego se procedio a normalizar los datos. \n",
    "\n",
    "Usando la funcion de `predictOneVsAll()`, viendo el resultado de precision nos da un **61.41461%** , un poco en diferencia a la anterior prediccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 61.41461%\n"
     ]
    }
   ],
   "source": [
    "X_test1_CR = X_testCR.copy()\n",
    "# print(X_test.shape)\n",
    "X_test1_CR = (X_test1_CR - mu_CR) / sigma_CR\n",
    "pred_train_CR = predictOneVsAll(all_theta_CR, X_test1_CR)\n",
    "print('Precision del conjunto de entrenamiento: {:.5f}%'.format(np.mean(pred_train_CR == y_testCR) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se puede hacer las predicciones usando directamente la funcion `sigmoid()`, y luego imprimimos 30 predicciones para ver que tanto se asemejan con nuestra Y predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15962, 24)\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 0\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 2, Real: 2\n",
      "Prediccion: 2, Real: 2\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 0, Real: 1\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 0, Real: 1\n",
      "Prediccion: 0, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 2, Real: 0\n",
      "Prediccion: 2, Real: 2\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 2, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 0\n",
      "Prediccion: 1, Real: 2\n",
      "Prediccion: 0, Real: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#usando el mu y sigma calculado anteriormente, para realizar la normalizacion de los datos de prueba\n",
    "X_test1_CR = (X_testCR.copy() - mu_CR) / sigma_CR\n",
    "X_test1_CR = np.concatenate([np.ones((len(X_test1_CR), 1)), X_test1_CR], axis=1)\n",
    "\n",
    "print(X_test1_CR.shape)\n",
    "\n",
    "#para este ejemplo, vamos a mostrar las predicciones de las primeras 30 predicciones y compararlas con las reales\n",
    "p = np.argmax(sigmoid(X_test1_CR.dot(all_theta_CR.T)), axis = 1)\n",
    "\n",
    "for i in range(30):\n",
    "    print(f\"Prediccion: {p[i]}, Real: {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Usando sin regularizacion\n",
    "\n",
    "En esta parte del laboratorio no se usara la parte de regularizacion, esto para ver como es el comportamiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Clasificacion Multiclase\n",
    "\n",
    "Carga de los datos para la clasificacion multiclase sin usar regularizacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]  X[:, 19]  X[:, 20]  X[:, 21]  X[:, 22]     Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "         3        25        12     15280      4194         3       7        15         4      5255        28         9      4015         3         2       563        34       236         2        51       130         5       211       1\n",
      "         3        34        12     65984      5279         8       3        24         4      5379        15        19      1286        12         2      1377        39       107         2       170       637         2       383       0\n",
      "         3        40        10     20664      1509         9       7        26         6      3650        58        31      2507         6         0      3515        30        97         2        99        63         5       279       1\n",
      "         4        29        15     34899      2923         3       5        15         6       591        16        31      1064         4         2      1553        31       178         2        92       274         3       197       0\n",
      "         4        48         5     19204      1660         5       7        13         3      3826        18        12      3627         7         2       504        27       361         1        35       211         6       210       1\n",
      "         5        25         5     33064      2741         8       3         6         7      4928        12        16      3897         5         2       788        25       216         2       144       208         6       212       1\n",
      "         3        20        10     18053      1231         5       6        13         7      1177        14        12      1195         7         2      1263        24        81         2        57     10000         6       295       1\n",
      "         6        32         8    131578     11206         2       3         3         2      1408        14         2       884        28         1       816        41       257         1       185       281         1       904       2\n",
      "         1        35        13     12876      4194         6       5        15         4      4546         1        19       682         1         2        53        41       351         1        40        22         6       270       1\n",
      "         4        55         4     11249      4194         3       3        12         1      4144        15         9       979         4         1       612        33         0         1         8        13         0       317       2\n",
      " \n",
      "El 80% de ejemplos para entrenamiento son la cantidad de: 63843 de ejemplos\n",
      "El 20% de ejemplos para pruebas son la cantidad de: 15962 de ejemplos\n",
      "La cantidad total de ejemplos es de: 79805 de ejemplos\n"
     ]
    }
   ],
   "source": [
    "#estos datos seran usados para el entrenamiento\n",
    "X_testSR = X_test.copy()\n",
    "y_testSR = y_test.copy()\n",
    "m_test_SR = len(y_testSR)\n",
    "\n",
    "#estos datos seran usados para el test\n",
    "X_trainSR = X_train.copy()\n",
    "y_trainSR = y_train.copy()\n",
    "m_train_SR = len(y_trainSR)\n",
    "\n",
    "#Visualizamos una cantidad de datos de entrenamiento\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]', 'X[:, 19]', 'X[:, 20]', 'X[:, 21]', 'X[:, 22]','Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}'.format(\n",
    "        X_trainSR[i, 0],\n",
    "        X_trainSR[i, 1],\n",
    "        X_trainSR[i, 2], \n",
    "        X_trainSR[i, 3], \n",
    "        X_trainSR[i, 4], \n",
    "        X_trainSR[i, 5], \n",
    "        X_trainSR[i, 6], \n",
    "        X_trainSR[i, 7], \n",
    "        X_trainSR[i, 8], \n",
    "        X_trainSR[i, 9], \n",
    "        X_trainSR[i, 10],\n",
    "        X_trainSR[i, 11],\n",
    "        X_trainSR[i, 12], \n",
    "        X_trainSR[i, 13], \n",
    "        X_trainSR[i, 14], \n",
    "        X_trainSR[i, 15], \n",
    "        X_trainSR[i, 16],\n",
    "        X_trainSR[i, 17],\n",
    "        X_trainSR[i, 18],\n",
    "        X_trainSR[i, 19], \n",
    "        X_trainSR[i, 20], \n",
    "        X_trainSR[i, 21], \n",
    "        X_trainSR[i, 22], \n",
    "        y_trainSR[i]\n",
    "    ))\n",
    "\n",
    "print(\" \")\n",
    "print('El 80% de ejemplos para entrenamiento son la cantidad de: {:.0f} de ejemplos'.format( len(X_train)))\n",
    "print('El 20% de ejemplos para pruebas son la cantidad de: {:.0f} de ejemplos'.format( len(X_test)))\n",
    "print('La cantidad total de ejemplos es de: {:.0f} de ejemplos'.format( len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Normalizacion de las caracteristicas\n",
    "\n",
    "Se hace uso de la funcion de `featureNormalize(X) ` donde se recibe un parametro de tipo matriz para normalizar cada dato dentro de ella, retornandome la **matriz normalizda**, **sigma(desviacion estandar)**, y mi **mu(media)**.\n",
    "\n",
    "Almacenando los datos normalizados en **X_norm** usando la funcion **featureNormaliza()**, normalizando los datos de X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]  X[:, 19]  X[:, 20]  X[:, 21]  X[:, 22]     Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "     -0.21     -0.97      0.98     -0.11     -0.00     -0.81      0.47      0.05      0.18      0.89      0.47     -0.10      1.21     -0.13      0.97     -0.75      0.33      0.31      0.86     -0.16     -0.26      1.01     -0.90       1\n",
      "     -0.21      0.00      0.98     -0.08      0.37      0.88     -0.89      1.09      0.18      0.95     -0.41     -0.05     -1.00     -0.08      0.97     -0.05      1.31     -0.82      0.86     -0.15     -0.00     -0.51     -0.10       0\n",
      "     -0.21      0.58      0.55     -0.11     -0.92      1.21      0.47      1.32      1.00      0.07      2.48     -0.00     -0.01     -0.11     -1.51      1.80     -0.47     -0.91      0.86     -0.16     -0.29      1.01     -0.58       1\n",
      "      0.22     -0.56      1.63     -0.10     -0.44     -0.81     -0.21      0.05      1.00     -1.48     -0.34     -0.00     -1.18     -0.12      0.97      0.10     -0.23     -0.20      0.86     -0.16     -0.18      0.00     -0.97       0\n",
      "      0.22      1.40     -0.54     -0.11     -0.87     -0.14      0.47     -0.18     -0.22      0.16     -0.21     -0.09      0.90     -0.11      0.97     -0.80     -1.04      1.40     -0.58     -0.17     -0.22      1.52     -0.91       1\n",
      "      0.66     -0.97     -0.54     -0.10     -0.50      0.88     -0.89     -0.98      1.41      0.72     -0.61     -0.07      1.12     -0.12      0.97     -0.55     -1.40      0.13      0.86     -0.15     -0.22      1.52     -0.90       1\n",
      "     -0.21     -1.49      0.55     -0.11     -1.01     -0.14      0.13     -0.18      1.41     -1.18     -0.48     -0.09     -1.07     -0.11      0.97     -0.15     -1.66     -1.05      0.86     -0.16      4.65      1.52     -0.51       1\n",
      "      1.09     -0.25      0.11     -0.03      2.39     -1.15     -0.89     -1.32     -0.63     -1.06     -0.48     -0.13     -1.33      0.00     -0.27     -0.53      1.64      0.49     -0.58     -0.15     -0.18     -1.01      2.35       2\n",
      "     -1.09      0.06      1.20     -0.12     -0.00      0.20     -0.21      0.05      0.18      0.53     -1.35     -0.05     -1.49     -0.14      0.97     -1.19      1.77      1.31     -0.58     -0.16     -0.31      1.52     -0.62       1\n",
      "      0.22      2.12     -0.76     -0.12     -0.00     -0.81     -0.89     -0.29     -1.04      0.32     -0.41     -0.10     -1.25     -0.12     -0.27     -0.71      0.20     -1.76     -0.58     -0.17     -0.31     -1.52     -0.40       2\n"
     ]
    }
   ],
   "source": [
    "X_norm_SR, mu_SR, sigma_SR = featureNormalize(X_trainSR)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]', 'X[:, 19]', 'X[:, 20]', 'X[:, 21]', 'X[:, 22]','Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:8.0f}'.format(\n",
    "        X_norm_SR[i, 0],\n",
    "        X_norm_SR[i, 1],\n",
    "        X_norm_SR[i, 2], \n",
    "        X_norm_SR[i, 3], \n",
    "        X_norm_SR[i, 4], \n",
    "        X_norm_SR[i, 5], \n",
    "        X_norm_SR[i, 6], \n",
    "        X_norm_SR[i, 7], \n",
    "        X_norm_SR[i, 8], \n",
    "        X_norm_SR[i, 9], \n",
    "        X_norm_SR[i, 10],\n",
    "        X_norm_SR[i, 11],\n",
    "        X_norm_SR[i, 12], \n",
    "        X_norm_SR[i, 13], \n",
    "        X_norm_SR[i, 14], \n",
    "        X_norm_SR[i, 15], \n",
    "        X_norm_SR[i, 16],\n",
    "        X_norm_SR[i, 17],\n",
    "        X_norm_SR[i, 18],\n",
    "        X_norm_SR[i, 19], \n",
    "        X_norm_SR[i, 20], \n",
    "        X_norm_SR[i, 21], \n",
    "        X_norm_SR[i, 22], \n",
    "        y_trainSR[i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Clasificacion One-vs-All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 24)\n",
      "Thetha 0  para la clase 0: -1.0815432135459961  ;  Thetha 0  para la clase 1: 0.14285349851581414  ;  Thetha 0  para la clase 2: -2.3711422465984513\n",
      "Thetha 1  para la clase 0: 0.0014111368182945564  ;  Thetha 1  para la clase 1: 0.016860057646807064  ;  Thetha 1  para la clase 2: -0.03736459358204417\n",
      "Thetha 2  para la clase 0: -0.06071942258364846  ;  Thetha 2  para la clase 1: 0.0071704012203908695  ;  Thetha 2  para la clase 2: 0.049803981495049006\n",
      "Thetha 3  para la clase 0: 0.007170505160669617  ;  Thetha 3  para la clase 1: -0.0011672879403555906  ;  Thetha 3  para la clase 2: -0.01486555887904792\n",
      "Thetha 4  para la clase 0: -0.024927809372523757  ;  Thetha 4  para la clase 1: 0.02115291750067745  ;  Thetha 4  para la clase 2: -0.0010770765438633222\n",
      "Thetha 5  para la clase 0: -0.09457664390799475  ;  Thetha 5  para la clase 1: -0.004293653625063567  ;  Thetha 5  para la clase 2: 0.12319884596775409\n",
      "Thetha 6  para la clase 0: -0.02054703063516854  ;  Thetha 6  para la clase 1: 0.15972887047427828  ;  Thetha 6  para la clase 2: -0.044983183877143694\n",
      "Thetha 7  para la clase 0: 0.1574746961694353  ;  Thetha 7  para la clase 1: 0.025964062288239265  ;  Thetha 7  para la clase 2: -0.6243253164984137\n",
      "Thetha 8  para la clase 0: 0.5457937345340298  ;  Thetha 8  para la clase 1: -0.20729153857000593  ;  Thetha 8  para la clase 2: -0.5822061767622966\n",
      "Thetha 9  para la clase 0: 0.06212975959781312  ;  Thetha 9  para la clase 1: 0.056642788283047946  ;  Thetha 9  para la clase 2: -0.21385326082197392\n",
      "Thetha 10  para la clase 0: -0.02523669791484894  ;  Thetha 10  para la clase 1: 0.025297914960569146  ;  Thetha 10  para la clase 2: -0.017038244226568397\n",
      "Thetha 11  para la clase 0: 0.30854474471642107  ;  Thetha 11  para la clase 1: -0.0050757284518135526  ;  Thetha 11  para la clase 2: -0.6243376519498803\n",
      "Thetha 12  para la clase 0: 0.0007755586262465692  ;  Thetha 12  para la clase 1: 0.010405687009344093  ;  Thetha 12  para la clase 2: -0.017678674524258954\n",
      "Thetha 13  para la clase 0: 0.032423781218203954  ;  Thetha 13  para la clase 1: -0.02957164457240077  ;  Thetha 13  para la clase 2: 0.015415940273339456\n",
      "Thetha 14  para la clase 0: 0.004828482709113114  ;  Thetha 14  para la clase 1: -0.0007042468608382296  ;  Thetha 14  para la clase 2: -0.008176201159699194\n",
      "Thetha 15  para la clase 0: -0.2185689480932435  ;  Thetha 15  para la clase 1: 0.723227804503468  ;  Thetha 15  para la clase 2: -0.9664264912970066\n",
      "Thetha 16  para la clase 0: 0.010831691911530683  ;  Thetha 16  para la clase 1: 0.12282976821085198  ;  Thetha 16  para la clase 2: -0.4220584621649492\n",
      "Thetha 17  para la clase 0: 0.01068732028255044  ;  Thetha 17  para la clase 1: -0.0065970109362938475  ;  Thetha 17  para la clase 2: -0.00715039142654965\n",
      "Thetha 18  para la clase 0: -0.11194292017172632  ;  Thetha 18  para la clase 1: -0.006518541761528678  ;  Thetha 18  para la clase 2: 0.1303913297169467\n",
      "Thetha 19  para la clase 0: 0.028233038389328963  ;  Thetha 19  para la clase 1: 0.11176256778915895  ;  Thetha 19  para la clase 2: -0.22133727259576466\n",
      "Thetha 20  para la clase 0: -0.009421485827696828  ;  Thetha 20  para la clase 1: 0.007029772609790896  ;  Thetha 20  para la clase 2: -0.0036931924577381595\n",
      "Thetha 21  para la clase 0: -0.0010918719893170097  ;  Thetha 21  para la clase 1: -0.009778259262745148  ;  Thetha 21  para la clase 2: 0.022260857527352552\n",
      "Thetha 22  para la clase 0: 0.16311163663400857  ;  Thetha 22  para la clase 1: -0.04467715168982217  ;  Thetha 22  para la clase 2: -0.18493573153338605\n",
      "Thetha 23  para la clase 0: 0.12751822577493413  ;  Thetha 23  para la clase 1: 0.005893761323565322  ;  Thetha 23  para la clase 2: -0.19914851013741666\n"
     ]
    }
   ],
   "source": [
    "all_theta_SR = oneVsAllSR(X_norm_SR, y_trainSR, num_labels)\n",
    "print(all_theta_CR.shape)\n",
    "\n",
    "#imprimimos todos los thetas para cada clase\n",
    "for i in range(all_theta_SR.shape[1]):\n",
    "    print(\"Thetha\",i,\" para la clase 0:\", all_theta_SR[0,i],\" ; \", \"Thetha\",i,\" para la clase 1:\", all_theta_SR[1,i],\" ; \", \"Thetha\",i,\" para la clase 2:\", all_theta_SR[2,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Validaciones\n",
    "Para hacer las validaciones correspondientes se hizo el uso siguiendo el consejo de 80/20, donde 80% es para la fase de entrenamiento, y 20% es para la fase de prueba.\n",
    "\n",
    "Para este caso de validacion se hizo uso de la funcion de `predictOneVsAll()` creada anteriormente, los siguiente fue normalizar nuestra `X_test` que son el 20% para pruebas, ahora se procedio a normalizarlo haciendo uso de *mu* y *sigma* calculado anteriormente en la funcion de normalizacion.\n",
    "\n",
    "luego se hace uso de `np.mean` donde nos calcula el promedio de los valores booleanos en el array resultante de la comparación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Con los datos de entrenamiento\n",
    "Para este caso se uso los datos de `X_norm` usando la funcion de `predictOneVsAll()`, viendo el resultado de precision nos da un **61.99897%** el cual esta muy lejos de ser un buen modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 61.99897%\n"
     ]
    }
   ],
   "source": [
    "# print(X_test.shape)\n",
    "pred_test_SR = predictOneVsAll(all_theta_SR, X_norm_SR)\n",
    "print('Precision del conjunto de entrenamiento: {:.5f}%'.format(np.mean(pred_test_SR == y_trainSR) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 con los datos de prueba\n",
    "Para este caso se uso los datos de `X_test`, luego se procedio a normalizar los datos. \n",
    "\n",
    "Usando la funcion de `predictOneVsAll()`, viendo el resultado de precision nos da un **62.23531%** , un poco en diferencia a la anterior prediccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 62.23531%\n"
     ]
    }
   ],
   "source": [
    "X_test1_SR = X_testSR.copy()\n",
    "# print(X_test.shape)\n",
    "X_test1_SR = (X_test1_SR - mu_SR) / sigma_SR\n",
    "pred_train_SR = predictOneVsAll(all_theta_SR, X_test1_SR)\n",
    "print('Precision del conjunto de entrenamiento: {:.5f}%'.format(np.mean(pred_train_SR == y_testSR) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se puede hacer las predicciones usando directamente la funcion `sigmoid()`, y luego imprimimos 30 predicciones para ver que tanto se asemejan con nuestra Y predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15962, 24)\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 0\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 2, Real: 2\n",
      "Prediccion: 2, Real: 2\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 0, Real: 1\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 0, Real: 1\n",
      "Prediccion: 0, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 2, Real: 0\n",
      "Prediccion: 2, Real: 2\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 2, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 0\n",
      "Prediccion: 1, Real: 2\n",
      "Prediccion: 0, Real: 1\n"
     ]
    }
   ],
   "source": [
    "#usando el mu y sigma calculado anteriormente, para realizar la normalizacion de los datos de prueba\n",
    "X_test1_SR = (X_testSR.copy() - mu_SR) / sigma_SR\n",
    "X_test1_SR = np.concatenate([np.ones((len(X_test1_SR), 1)), X_test1_SR], axis=1)\n",
    "\n",
    "print(X_test1_SR.shape)\n",
    "\n",
    "#para este ejemplo, vamos a mostrar las predicciones de las primeras 30 predicciones y compararlas con las reales\n",
    "p = np.argmax(sigmoid(X_test1_SR.dot(all_theta_SR.T)), axis = 1)\n",
    "\n",
    "for i in range(30):\n",
    "    print(f\"Prediccion: {p[i]}, Real: {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En esta parte se presentaran las conclusiones de acuerdo a las experiencias vistas en este laboratorio aplicando regularizacion y sin aplicar regularizacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cual es el mejor?\n",
    "\n",
    "Se comparó el desempeño de modelos de regresión logistica one-vs-all con y sin regularización, se pueden extraer varias conclusiones significativas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Impacto de la regularización en la precisión del modelo:\n",
    "\n",
    " Se observa que la regularización puede tener un efecto en la precisión del modelo. En algunos casos, la regularización puede mejorar la precisión del modelo al reducir el sobreajuste (overfitting),\n",
    " especialmente cuando se tienen conjuntos de datos pequeños o altamente ruidosos. \n",
    " \n",
    " Sin embargo, en conjuntos de datos más grandes o con menos ruido, la regularización puede no proporcionar mejoras significativas en la precisión y podría incluso degradarla.\n",
    "\n",
    " Para este caso se hizo la comparacion entre la preciscion de ambos modelos, con y sin regularizacion:\n",
    "\n",
    "| Tipo  | Precision del modelo con regularizacion| Presicion del modelo sin regularizacion| Dieferencia entre ambos|\n",
    "|---------|------|---------|-----------|\n",
    "| Con los datos de entrenamiento |61.20483%  | 61.99897% | -0.79414% |\n",
    "| Con los datos de prueba | 61.41461%  | 62.23531% | -0.8207% |\n",
    "\n",
    "Sepodemos observar que tanto la precisión del modelo con regularización como la del modelo sin regularización son bastante similares en ambos conjuntos de datos, tanto en los datos de entrenamiento como en los de prueba. Sin embargo, hay una ligera diferencia entre ambos en cada conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Tiempo de entrenamiento\n",
    "\n",
    "En algunos casos, la regularización puede aumentar el tiempo de entrenamiento del modelo debido a la necesidad de calcular los términos adicionales de penalización en la función de costo y actualizar los coeficientes del modelo de manera iterativa.\n",
    "\n",
    "Haciendo una tabla para ver los cambios:\n",
    "\n",
    "| Modelo  | Tiempo de entrenamiento del modelo con regularizacion | Tiempo de entrenamiento del modelo sin regularizacion |Dieferencia entre ambos|\n",
    "|---------|------|---------|-----------|\n",
    "| Clasificacion Multiclase |0.2 seg  | 0.3 seg | -0.1 seg|\n",
    "\n",
    "Como se puede observar el tiempo de entrenamiento para el modelo usando regularizacion es con muy poco menor al usado sin regularizacion, con una diferencia del 0.1 segundos. Esto sugiere que la regularización puede haber contribuido a una reducción en el tiempo de entrenamiento del modelo. Esto puede ser atribuido a la capacidad de la regularización para simplificar el modelo y reducir la complejidad, lo que a su vez puede conducir a un proceso de entrenamiento más rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Entonces cual es el mejor?\n",
    "\n",
    "Una vez realizadas las comparaciones del desempeño de modelos con y sin regularización en términos de tiempo de entrenamiento y precisión, se puede determinar que el mejor modelo es aquel que aplica regularización.\n",
    "\n",
    "**¿Por qué?**\n",
    "\n",
    "El tiempo de entrenamiento es menor en el modelo con regularización, a pesar de que su precisión es ligeramente inferior a la del modelo sin aplicar regularización. En muchos casos, especialmente cuando se trabaja con grandes conjuntos de datos, el tiempo de entrenamiento puede ser un factor crítico a considerar, ya que puede afectar significativamente la eficiencia del proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuales son los mejores hiperparametros?\n",
    "\n",
    "Se eligio aquellos hiperparametros de acuerdo al tiempo y presicion que nos daba el modelo:\n",
    "\n",
    "- **Numero de iteraciones.-** se eligio como una cantidad de **20000** iteraciones, esto guiandonos con la precision y el tiempo que tardaba en entrenar el modelo, si se elegia un numero de iteraciones arriba de 20000 el tiempo de entrenamiento era muy alto, y la presicion incluso era demasiado alejado del 100%.\n",
    "\n",
    "- **Lambda.-** Para el hiperparametro **lambda** se uso el valor de **1000**, igualmente se siguio las recomendaciones que el hiperparametro lambda podria estar entre 10, 100 o 1000, se hizo la prueba con cada uno pero el que mejor resultados pero con mayor tiempo de entrenamiento y procesamiento nos dio fue el valor de un lamdda de *1000*. Se hizo la prueba con el valor de 10 lo cual nos daba un precision cercana a 62.24%, luego se probo con el valor de 100 el cual nos daba una precision de 61.998% y finalmente se uso el valor de 1000 y este nos dio una presicion del 61.20483%, el cual se selecciono el valor de 1000 para lambda, esto porque se busca un parametro un poco lejano a 0. Tambien se hizo la prueba con un valor de lambda cercano a cero, y nos genero una presicion igual al de la presicion del modelo sin regularizar, mientras que si usabamos un valor lambda negativo nos generaba una grafica contraria al de la curva esperada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cual asumirias en una determinada circunstancia?\n",
    "\n",
    "Además de la mínima diferencia en los tiempos de entrenamiento y la precisión entre ambos modelos, la regularización proporciona una ventaja adicional al ayudar a prevenir el sobreajuste o overfitting, especialmente cuando se incrementa el número de iteraciones o se trabaja con conjuntos de datos más complejos. La regularización actúa como una medida preventiva para garantizar que el modelo generalice bien a datos no vistos y evite ajustarse demasiado a los datos de entrenamiento.\n",
    "\n",
    "Dado que el tiempo de entrenamiento es corto para ambos modelos y el impacto en los recursos computacionales es mínimo, aplicar regularización es una elección sensata que puede mejorar la capacidad del modelo para generalizar a nuevos datos sin comprometer significativamente el rendimiento del entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
